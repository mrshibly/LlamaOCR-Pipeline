{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Bangla/English OCR & IE Pipeline (Stable & Interactive)\n",
    "This notebook implements a complete Document AI pipeline with robust error handling and multi-threaded API support for Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install paddlepaddle-gpu\n",
    "!pip install paddleocr opencv-python-headless fastapi uvicorn pyngrok pydantic python-multipart requests\n",
    "print('‚úÖ Dependencies installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Ollama (Local LLM)\n",
    "Run this to pull the extraction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Start Ollama server in background\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(5)\n",
    "\n",
    "# Pull model\n",
    "!ollama pull llama3.2:1b\n",
    "print('‚úÖ Ollama is ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Core Logic (OCR & IE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "import unicodedata\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# --- üß† Singleton OCR Initialization ---\n",
    "# This prevents Colab crashes when running the cell multiple times\n",
    "if 'ocr' not in globals():\n",
    "    print(\"Initializing PaddleOCR (this may take a minute)...\")\n",
    "    try:\n",
    "        ocr = PaddleOCR(use_angle_cls=True, lang='bn', use_gpu=True)\n",
    "        print(\"‚úÖ PaddleOCR initialized.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå OCR Init Error: {e}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è PaddleOCR already initialized.\")\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None: raise ValueError(\"Could not read image.\")\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "    return thresh\n",
    "\n",
    "def run_ocr(image_path):\n",
    "    result = ocr.ocr(image_path, cls=True)\n",
    "    text_lines = [line[1][0] for line in result[0]] if (result and result[0]) else []\n",
    "    full_text = \"\\n\".join(text_lines)\n",
    "    return unicodedata.normalize(\"NFKC\", full_text)\n",
    "\n",
    "def extract_info(text):\n",
    "    data = {}\n",
    "    # Regex Patterns\n",
    "    nid_match = re.search(r'(\\d{10}|\\d{13}|\\d{17})', text)\n",
    "    if nid_match: data['nid_number'] = nid_match.group(1)\n",
    "    \n",
    "    date_match = re.search(r'(\\d{2}[-/\\.]\\d{2}[-/\\.]\\d{4})', text)\n",
    "    if date_match: data['date_of_birth'] = date_match.group(1)\n",
    "    \n",
    "    # Ollama Extraction\n",
    "    prompt = f\"Extract person name, father name, mother name, and address from this text. Return valid JSON only.\\n\\nText: {text}\"\n",
    "    try:\n",
    "        payload = {\"model\": \"llama3.2:1b\", \"prompt\": prompt, \"stream\": False, \"format\": \"json\"}\n",
    "        resp = requests.post(\"http://localhost:11434/api/generate\", json=payload, timeout=30)\n",
    "        data.update(json.loads(resp.json().get(\"response\", \"{}\")))\n",
    "    except Exception as e:\n",
    "        data['llm_error'] = str(e)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. FastAPI Deployment (Interactive)\n",
    "This cell starts the API in a background thread so you can continue using the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.responses import JSONResponse\n",
    "from pyngrok import ngrok\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import shutil\n",
    "import os\n",
    "import traceback\n",
    "import threading\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/extract\")\n",
    "async def api_extract(file: UploadFile = File(...)):\n",
    "    temp_file = f\"temp_{file.filename}\"\n",
    "    try:\n",
    "        print(f\"üì• Received: {file.filename}\")\n",
    "        with open(temp_file, \"wb\") as buffer:\n",
    "            shutil.copyfileobj(file.file, buffer)\n",
    "        \n",
    "        clean = preprocess_image(temp_file)\n",
    "        cv2.imwrite(\"clean.jpg\", clean)\n",
    "        \n",
    "        print(\"üîç OCR Running...\")\n",
    "        text = run_ocr(\"clean.jpg\")\n",
    "        \n",
    "        print(\"üß¨ IE Running...\")\n",
    "        structured = extract_info(text)\n",
    "        \n",
    "        return {\"status\": \"success\", \"structured_data\": structured, \"raw_text\": text}\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_trace = traceback.format_exc()\n",
    "        print(f\"‚ùå ERROR: {error_trace}\")\n",
    "        return JSONResponse(\n",
    "            status_code=500, \n",
    "            content={\"status\": \"error\", \"message\": str(e), \"traceback\": error_trace}\n",
    "        )\n",
    "    finally:\n",
    "        if os.path.exists(temp_file): os.remove(temp_file)\n",
    "\n",
    "# üîë ngrok Authtoken\n",
    "!ngrok authtoken 38CmbCTAS2yWNSsMba5alNmsRly_qNNmEdeqcf7xWBeyoN7A\n",
    "\n",
    "def start_api():\n",
    "    nest_asyncio.apply()\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "try:\n",
    "    # Kill existing tunnels to avoid port conflicts\n",
    "    tunnels = ngrok.get_tunnels()\n",
    "    for t in tunnels: ngrok.disconnect(t.public_url)\n",
    "    \n",
    "    public_url = ngrok.connect(8000).public_url\n",
    "    print(f\"\\nüöÄ API Live at: {public_url}/docs\")\n",
    "    \n",
    "    # Start server in background thread\n",
    "    threading.Thread(target=start_api, daemon=True).start()\n",
    "    print(\"‚úÖ FastAPI is running in the background.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Startup failed: {e}\")"
   ]
  }
 ],
 "metadata": {
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.10.12"
 }
},
 "nbformat": 4,
 "nbformat_minor": 4
}
